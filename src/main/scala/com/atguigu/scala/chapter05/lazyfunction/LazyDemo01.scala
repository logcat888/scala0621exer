package com.atguigu.scala.chapter05.lazyfunction

/**
 * 惰性函数，类似于java中的懒汉式，只有被真正调用时再加载，java中称为懒加载（延迟加载）
 * 惰性的理解：
 *   1. val res = sum(10,20) 是实时被调用
 *   2. lazy val res = sum(10,20) 是res只加上一个引用，在缓冲层加载了10,20，放入到缓存队列中，没有执行，
 *           因为将来我们的执行过程可能很费时间，比如大数据的排序。在真正使用res时，才被执行。把数据从缓存队列中
 *           拎出来，放到计算队列中。
 *
 * 注意事项和细节：
 *   1）lazy不能修饰var类型的变量。这说明他在预加载时，这个变量就不能变了，他是线程安全的
 *   2）不但是在调用函数时，加了lazy会导致函数的执行被推迟，我们在声明一个变量时，如果给声明了lazy，那么变量值的分配也会推迟。
 *      比如：lazy val i = 10 ，并未立即分配内存空间，只有在使用时才能分配内存空间
 *   3）lazy在大数据的使用，根据自己的业务逻辑，这个数据需要大量的计算，但是并不是马上就需要把数据推给用户，
 *      而是在用户使用时，我在临时的去算。而且Spark是内存级的框架，即使我们刚刚加载进去，也是秒级反应。所以没有
 *      必要把数据提前计算入库，你入库后可能别人根本就没有使用，就会造成浪费。 所以将来的应用场景就是，
 *      如果将来有一个大数据的计算，你希望当用户调用时才计算，就把这个函数加上一个lazy，你的性能就会大大提升。 就是加上了这一个简单的关键字，
 *      性能就是天壤之别。
 * @author chenhuiup
 * @create 2020-09-13 11:12
 */
object LazyDemo01 {
  def main(args: Array[String]): Unit = {
    lazy val res = sum(10,20)
    println("----------------")
    println("res=" + res)

  }
  //sum函数，返回和
  def sum(n1:Int,n2:Int):Int={
    println("sum()执行了...")
    return n1 + n2
  }

}
